# ═══════════════════════════════════════════════════════════════════════════════
# SECURITY WARNING
# ═══════════════════════════════════════════════════════════════════════════════
# Never commit .env.local or any file containing real API keys to git.
# Rotate any key that is accidentally exposed immediately.
# This file (.env.example) is safe to commit — all values are obvious placeholders.
# ═══════════════════════════════════════════════════════════════════════════════

# ─────────────────────────────────────────────
# APP / NEXT.JS CORE
# ─────────────────────────────────────────────

# The canonical public URL of this deployment.
# Used by Next.js for generating absolute URLs, OG image links, and API base URLs.
# In Vercel deployments this is auto-set to VERCEL_URL; set it explicitly for
# custom domains or local dev.
# Example: https://your-app.vercel.app  |  http://localhost:3000
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Node environment. Set automatically by Next.js to "development" | "production" | "test".
# DO NOT set this manually in .env.local — Next.js controls it.
# Documented here for reference only.
# NODE_ENV=development

# ─────────────────────────────────────────────
# AI / LLM PROVIDERS
# The pipeline is currently fully simulated. Uncomment and populate these
# when wiring real LLM calls into lib/pipeline.ts or lib/agents.ts.
# ─────────────────────────────────────────────

# OpenAI API Key — used for GPT-4o / o1 model calls by any agent.
# Get yours at: https://platform.openai.com/api-keys
# Server-side only — NEVER prefix with NEXT_PUBLIC_.
OPENAI_API_KEY=your_openai_api_key_here

# OpenAI Organization ID (optional) — ties API usage to a specific org/billing account.
# Get yours at: https://platform.openai.com/account/org-settings
OPENAI_ORG_ID=your_openai_org_id_here

# Anthropic API Key — used for Claude model calls (claude-3-5-sonnet, claude-opus, etc.).
# Get yours at: https://console.anthropic.com/account/keys
# Server-side only — NEVER prefix with NEXT_PUBLIC_.
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ─────────────────────────────────────────────
# ACADEMIC & WEB SEARCH APIs
# These power real searches in Stage 2 (Research) and Stage 3 (Verification).
# The Verification Specialist agent system prompt explicitly calls for
# "Web search validation (Google Scholar, Bing Academic)".
# ─────────────────────────────────────────────

# Serper API Key — Google Search results via serper.dev (recommended Google Scholar proxy).
# Used by: Verification Specialist (web_search check), Research Analyst.
# Get yours at: https://serper.dev  (free tier: 2,500 queries/month)
SERPER_API_KEY=your_serper_api_key_here

# Bing Web Search API Key — Microsoft Azure Cognitive Services.
# Used by: Verification Specialist ("Bing Academic" check in system prompt).
# Get yours at: https://portal.azure.com → Cognitive Services → Bing Search v7
BING_SEARCH_API_KEY=your_bing_search_api_key_here

# Bing Search API Endpoint (optional override).
# Default: https://api.bing.microsoft.com/v7.0/search
BING_SEARCH_ENDPOINT=https://api.bing.microsoft.com/v7.0/search

# ─────────────────────────────────────────────
# SPECIALIZED ACADEMIC DATABASE APIs
# These map directly to the sources referenced in lib/pipeline.ts SOURCE_META
# and lib/agents.ts AGENT_DEFINITIONS skills lists.
# ─────────────────────────────────────────────

# NCBI E-utilities API Key — enables PubMed/NCBI searches (Stage 2: Research Analyst).
# Without a key: 3 requests/second. With a key: 10 requests/second.
# Free — get yours at: https://www.ncbi.nlm.nih.gov/account/
# Used for: "Academic database search (PubMed, IEEE, JSTOR)" in agent skills.
PUBMED_API_KEY=your_ncbi_eutils_api_key_here

# CrossRef API "Polite Pool" token — enables faster, prioritized DOI lookups.
# Used by: Verification Specialist (DOI cross-validation in poison-shield.ts).
# Free — register your email at: https://www.crossref.org/documentation/retrieve-metadata/rest-api/
# The token is simply your registered email address.
CROSSREF_MAILTO=your_email@example.com

# IEEE Xplore API Key — direct access to IEEE journal and conference papers.
# Used by: Research Analyst ("Academic database search (PubMed, IEEE, JSTOR)").
# Free tier available — get yours at: https://developer.ieee.org/
IEEE_API_KEY=your_ieee_xplore_api_key_here

# Semantic Scholar API Key — open academic graph, good ArXiv + ACM coverage.
# Used by: Research Analyst (working_code / reputable_org source types).
# Free — get yours at: https://www.semanticscholar.org/product/api#api-key-form
SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_api_key_here

# ─────────────────────────────────────────────
# CODE REPOSITORY SEARCH
# ─────────────────────────────────────────────

# GitHub Personal Access Token — enables authenticated GitHub search (5,000 req/hr vs 60).
# Used by: Research Analyst ("working_code" source type in SOURCE_META →
#   https://github.com/search?q=... in pipeline.ts).
# Get yours at: https://github.com/settings/tokens
# Minimum scopes: public_repo (read-only) or no scopes for public-only access.
GITHUB_TOKEN=your_github_personal_access_token_here

# ─────────────────────────────────────────────
# VERCEL & DEPLOYMENT
# ─────────────────────────────────────────────

# Vercel Analytics ID — @vercel/analytics is already installed and <Analytics />
# is already mounted in app/layout.tsx.
# On Vercel deployments: this is injected AUTOMATICALLY — you do NOT need to set it.
# Only set manually for: self-hosted deployments or custom analytics configurations.
# Get yours at: https://vercel.com/dashboard → your project → Analytics tab
NEXT_PUBLIC_VERCEL_ANALYTICS_ID=your_vercel_analytics_id_here

# Vercel Deployment URL — auto-injected by Vercel as VERCEL_URL (no NEXT_PUBLIC_ prefix,
# so not accessible client-side). Use NEXT_PUBLIC_APP_URL above for client-side URL needs.
# Documented here for reference — do NOT set manually in .env.local.
# VERCEL_URL=your-project.vercel.app

# ─────────────────────────────────────────────
# PIPELINE CONFIGURATION (optional tuning)
# ─────────────────────────────────────────────

# Maximum user request length accepted by /api/pipeline.
# Default: 5000 (enforced in app/api/pipeline/route.ts).
# Increase only if you expect very long research prompts.
# PIPELINE_MAX_REQUEST_LENGTH=5000

# AI model to use for agent calls (when LLM integration is wired).
# Affects cost and response quality. Agents defined in lib/agents.ts.
# Recommended: gpt-4o | claude-3-5-sonnet-20241022
# AI_MODEL=gpt-4o

# Temperature for LLM agent calls (0.0 = deterministic, 1.0 = creative).
# Verification/Scientific agents should use lower values (0.1–0.3).
# Brainstorm/PMOPS agents can use higher values (0.6–0.8).
# AI_TEMPERATURE=0.3
